{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.random.normal([4,784])\n",
    "\n",
    "net = tf.keras.layers.Dense(512)\n",
    "#只需要指定输出的维度，输入时的维度会自动计算！！！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 512])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = net(x)\n",
    "out.shape#TensorShape([4, 512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([784, 512]), TensorShape([512]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.kernel.shape,net.bias.shape\n",
    "#(TensorShape([784, 512]), TensorShape([512]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([4, 10]), TensorShape([10]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = tf.keras.layers.Dense(10)\n",
    "net.get_weights()#[]\n",
    "net.build(input_shape=(None,4))\n",
    "net.kernel.shape,net.bias.shape\n",
    "#(TensorShape([4, 10]), TensorShape([10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 2)                 8         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 6         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 2)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20\n",
      "Trainable params: 20\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "dense_2/kernel:0 (3, 2)\n",
      "dense_2/bias:0 (2,)\n",
      "dense_3/kernel:0 (2, 2)\n",
      "dense_3/bias:0 (2,)\n",
      "dense_4/kernel:0 (2, 2)\n",
      "dense_4/bias:0 (2,)\n"
     ]
    }
   ],
   "source": [
    "x = tf.random.normal([2,3])\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(2,activation='relu'),\n",
    "    keras.layers.Dense(2,activation='relu'),\n",
    "    keras.layers.Dense(2),\n",
    "])\n",
    "model.build(input_shape=[None,3])#创建参数\n",
    "model.summary()#查看网络结构\n",
    "\n",
    "#手动查看\n",
    "for p in model.trainable_variables:\n",
    "    print(p.name,p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n(<tf.Tensor: shape=(), dtype=float32, numpy=1.6195879>,\\n <tf.Tensor: shape=(), dtype=float32, numpy=1.6195879>,\\n <tf.Tensor: shape=(), dtype=float32, numpy=1.6195879>)\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = tf.constant([1,2,3,0,2])\n",
    "y = tf.one_hot(y,depth=4)\n",
    "y = tf.cast(y,tf.float32)\n",
    "\n",
    "out = tf.random.normal([5,4])\n",
    "\n",
    "loss1 = tf.reduce_mean(tf.square(y-out))\n",
    "loss2 = tf.square(tf.norm(y-out))/20\n",
    "loss3 = tf.reduce_mean(tf.losses.MSE(y,out))\n",
    "loss1,loss2,loss3\n",
    "'''\n",
    "(<tf.Tensor: shape=(), dtype=float32, numpy=1.6195879>,\n",
    " <tf.Tensor: shape=(), dtype=float32, numpy=1.6195879>,\n",
    " <tf.Tensor: shape=(), dtype=float32, numpy=1.6195879>)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=2.0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.fill([4],0.25)\n",
    "a*tf.math.log(a)/tf.math.log(2.)\n",
    "-tf.reduce_sum(a*tf.math.log(a)/tf.math.log(2.))#2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1.3567796>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant([0.1,0.1,0.1,0.7])\n",
    "a*tf.math.log(a)/tf.math.log(2.)\n",
    "-tf.reduce_sum(a*tf.math.log(a)/tf.math.log(2.))#numpy=1.3567796"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=2.3025842>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.losses.categorical_crossentropy([0,1,0,0],[0.25,0.25,0.25,0.25])\n",
    "#<tf.Tensor: shape=(), dtype=float32, numpy=1.3862944>\n",
    "tf.losses.categorical_crossentropy([0,1,0,0],[0.1,0.8,0.1,0.1])\n",
    "#<tf.Tensor: shape=(), dtype=float32, numpy=0.3184537>\\\n",
    "#类的形式\n",
    "tf.losses.BinaryCrossentropy()([1],[0.1])\n",
    "#<tf.Tensor: shape=(), dtype=float32, numpy=2.3025842>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=2.0>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = tf.constant(1.)\n",
    "x = tf.constant(2.)\n",
    "y = x*w\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch([w])\n",
    "    y2=x*w\n",
    "grad1 = tape.gradient(y,[w])#[None]\n",
    "grad1\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch([w])\n",
    "    y2=x*w\n",
    "grad1 = tape.gradient(y2,[w])#[<tf.Tensor: shape=(), dtype=float32, numpy=2.0>]\n",
    "grad1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.GradientTape() as t1:\n",
    "#     with tf.GradientTape() as t2:\n",
    "#         y = x*w+b\n",
    "#     dy_dw,dy_db = t2.gradient(y,[w,b])\n",
    "# d2y_fw2 = t1.gradient(dy_dw,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n[<tf.Tensor: shape=(10,), dtype=float64, numpy=\\n array([4.53958077e-05, 4.18591319e-04, 3.83620191e-03, 3.32587242e-02,\\n        1.86326443e-01, 1.86326443e-01, 3.32587242e-02, 3.83620191e-03,\\n        4.18591319e-04, 4.53958077e-05])>]\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.linspace(-10,10,10)\n",
    "with tf.GradientTape() as tape:\n",
    "    #对于tf.constant类型的变量，也可以使用tape.watch加入自动求导记录里\n",
    "    tape.watch(a)\n",
    "    y = tf.sigmoid(a)\n",
    "grads = tape.gradient(y,[a])\n",
    "grads\n",
    "'''\n",
    "[<tf.Tensor: shape=(10,), dtype=float64, numpy=\n",
    " array([4.53958077e-05, 4.18591319e-04, 3.83620191e-03, 3.32587242e-02,\n",
    "        1.86326443e-01, 1.86326443e-01, 3.32587242e-02, 3.83620191e-03,\n",
    "        4.18591319e-04, 4.53958077e-05])>]\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 3), dtype=float32, numpy=\n",
       "array([[ 0.03861355, -0.03457694, -0.00403661],\n",
       "       [ 0.02824939, -0.02418399, -0.00406542],\n",
       "       [ 0.03575942, -0.034534  , -0.00122541],\n",
       "       [ 0.01089776, -0.01278827,  0.00189052]], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x= tf.random.normal([2,4])\n",
    "w=tf.random.normal([4,3])\n",
    "b = tf.zeros([3])\n",
    "y = tf.constant([2,0])\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch([w,b])\n",
    "    prob = tf.nn.softmax(x@w+b,axis=1)\n",
    "    loss = tf.reduce_mean(tf.losses.MSE(tf.one_hot(y,depth=3),prob))\n",
    "    \n",
    "grads = tape.gradient(loss,[w,b])\n",
    "grads[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 3), dtype=float32, numpy=\n",
       "array([[-0.29003704,  0.24017723,  0.04985982],\n",
       "       [-0.14264886, -0.41502684,  0.5576757 ],\n",
       "       [ 0.00087503, -0.44100258,  0.44012755],\n",
       "       [-0.13506618, -0.14862609,  0.28369227]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x= tf.random.normal([2,4])\n",
    "w=tf.random.normal([4,3])\n",
    "b = tf.zeros([3])\n",
    "y = tf.constant([2,0])\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch([w,b])\n",
    "    logits = x@w+b\n",
    "    loss =  tf.reduce_mean(tf.losses.categorical_crossentropy(tf.one_hot(y,depth=3),logits,from_logits=True))\n",
    "    \n",
    "grads = tape.gradient(loss,[w,b])\n",
    "grads[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 1), dtype=float32, numpy=\n",
       "array([[-0.01534693],\n",
       "       [ 0.02782919],\n",
       "       [-0.03759802]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.normal([1,3]) \n",
    "w = tf.ones([3,1])\n",
    "b = tf.ones([1])\n",
    "y = tf.constant([1])\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch([w,b])\n",
    "    prob = tf.sigmoid(x@w+b)\n",
    "    loss = tf.reduce_mean(tf.losses.MSE(y,prob))\n",
    "    \n",
    "grads = tape.gradient(loss,[w,b])\n",
    "grads[0]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2e8db0730c91600a5349938b5440aa07dc44fbf5b422a40c9df5fa4ade778ff1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
